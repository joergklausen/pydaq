{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import hvplot\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "from hvplot.plotting import scatter_matrix\n",
    "\n",
    "from nrbdaq.instr.ae31 import AE31\n",
    "from nrbdaq.instr.avo import compile_data as avo_compile_data\n",
    "from nrbdaq.utils.utils import load_config\n",
    "\n",
    "incoming = '/product_data/data/pay/Kenya/NRB/incoming'\n",
    "processed = '/product_data/data/pay/Kenya/NRB/processed'\n",
    "\n",
    "config = load_config('nrbdaq.yml')\n",
    "config['AE31']['data'] = os.path.join(incoming, 'ae31')\n",
    "config['AE31']['archive'] = processed\n",
    "ae31 = AE31(config=config)\n",
    "df_ae31 = ae31.compile_data()\n",
    "\n",
    "stations = ['kmd_hq_nairobi']#, 'huduma_center_bomet', 'mogogosiek_tea_factory_bomet']\n",
    "\n",
    "avo = avo_compile_data(stations=stations, \n",
    "                    source=os.path.join(incoming, 'avo'), \n",
    "                    target=processed)\n",
    "\n",
    "df_avo_daily = avo['kmd_hq_nairobi']['daily']\n",
    "df_avo_hourly = avo['kmd_hq_nairobi']['hourly']\n",
    "df_avo_instant = avo['kmd_hq_nairobi']['instant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate AE31 data to hourly median values\n",
    "df_ae31_hourly = df_ae31.sort(by='dtm').group_by_dynamic(index_column='dtm', every='1h', closed='right').agg(pl.all().exclude('dtm').median())\n",
    "vars_ae31 = ['UV370', 'B470', 'G520', 'Y590', 'R660', 'IR880', 'IR950', ]\n",
    "# convert from ng/m3 to µg/m3\n",
    "df_ae31_hourly = df_ae31_hourly.with_columns(pl.col(vars_ae31) / 1000)\n",
    "\n",
    "# sort AVO data by dtm\n",
    "# df_avo_hourly = df_avo_hourly.sort(by='dtm')\n",
    "vars_avo = ['pm1', 'pm25', 'pm10']\n",
    "\n",
    "# combine data \n",
    "df = pl.concat([df_ae31_hourly.select(['dtm'] + vars_ae31), df_avo_hourly.select(['dtm'] + vars_avo)], how='align')\n",
    "\n",
    "# Save results\n",
    "df.write_parquet(file=os.path.join('results',  f\"{stations[0]}.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate scatter matrix plot\n",
    "df_pd = df.select(pl.exclude('dtm')).to_pandas()\n",
    "figure = scatter_matrix(df_pd, alpha=0.2)\n",
    "hvplot.show(figure)\n",
    "\n",
    "# Save results\n",
    "# hvplot.save(obj=figure, filename=os.path.join('results', f\"{stations[0]}_scatter_matrix.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate time series plot\n",
    "df_pd = df.to_pandas()\n",
    "color_ae31 = ['purple', 'darkblue', 'green', 'gold', 'red', 'black', 'brown']\n",
    "color_avo = ['darkgray', 'gray', 'lightgray']\n",
    "\n",
    "# get scaling factor for AVO data so that they can be plotted on the same graph as AE31 data\n",
    "avo_max = max([df[x].max() for x in vars_avo]) # µg/m3\n",
    "ae31_max = max([df[x].max() for x in vars_ae31]) # µg/m3\n",
    "f = 10**round(math.log10(ae31_max / avo_max), 0)\n",
    "\n",
    "df_pd[vars_avo] = f * df_pd[vars_avo]\n",
    "vars_avo_new = [f\"{x} [x {f}]\" for x in vars_avo]\n",
    "df_pd.rename(columns=dict(zip(vars_avo, vars_avo_new)), inplace=True)\n",
    "\n",
    "# Plot time series\n",
    "plot_ae31 = df_pd.hvplot(x='dtm', y=vars_ae31, color=color_ae31, legend=True, yaxis='left', \n",
    "                         width=1200, height=500, ylabel=f\"Concentration [µg/m3]\",\n",
    "                         title='KMD HQ Nairobi, Dagoretti Corner')\n",
    "plot_avo = df_pd.hvplot(x='dtm', y=vars_avo_new, color=color_avo, legend=True, yaxis='left')\n",
    "figure = plot_ae31 * plot_avo\n",
    "hvplot.show(figure)\n",
    "\n",
    "# Save results\n",
    "# hvplot.save(obj=figure, filename=os.path.join('results', f\"{stations[0]}_time_series.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate matrix of plots of diurnal variation\n",
    "\n",
    "# Function to compute widths based on the number of data points per hour\n",
    "# def compute_widths(hour_counts):\n",
    "#     total_counts = sum(hour_counts)\n",
    "#     return [10* count / total_counts for count in hour_counts]\n",
    "# Function to compute widths based on the number of data points per hour and the number of days\n",
    "# Function to compute widths based on the number of data points per hour, \n",
    "# the number of days, and the total number of data points\n",
    "# def compute_widths(data, total_data_points, dtm='dtm'):\n",
    "#     # Calculate the number of unique days in the current scenario\n",
    "#     num_days = data.select(pl.col(dtm)).n_unique()\n",
    "    \n",
    "#     # Group by hour to calculate the number of data points in each hour\n",
    "#     hour_counts = data.group_by('hour').agg(pl.len().alias('count'))\n",
    "    \n",
    "#     # Calculate the proportion of data points for each hour relative to the current scenario\n",
    "#     total_scenario_points = hour_counts.select(pl.col('count')).sum()\n",
    "#     hour_counts = hour_counts.with_columns(\n",
    "#         (pl.col('count') / total_scenario_points).alias('relative_width_in_scenario')\n",
    "#     )\n",
    "    \n",
    "#     # Scale the relative widths by the proportion of data points in the current scenario to the total data points\n",
    "#     relative_scenario_proportion = total_scenario_points / total_data_points\n",
    "#     hour_counts = hour_counts.with_columns(\n",
    "#         (pl.col('relative_width_in_scenario') * relative_scenario_proportion).alias('final_width')\n",
    "#     )\n",
    "    \n",
    "#     total_final_width = hour_counts.select(pl.col('final_width')).sum().item()\n",
    "    \n",
    "#     # Normalize the final widths so that they sum to 1\n",
    "#     return (hour_counts['final_width'] / total_final_width).to_numpy()\n",
    "\n",
    "# extract data period\n",
    "start = df['dtm'].min()\n",
    "end = df['dtm'].max()\n",
    "\n",
    "# Extract the hour and the weekday\n",
    "df_all = df.with_columns([\n",
    "    pl.col('dtm').dt.hour().alias('hour'),\n",
    "    pl.col('dtm').dt.weekday().alias('weekday')\n",
    "])\n",
    "\n",
    "# Define filters for the scenarios\n",
    "# all_data = df\n",
    "df_weekdays = df_all.filter(pl.col('weekday').is_between(0, 4))  # Monday to Friday\n",
    "df_weekend = df_all.filter(pl.col('weekday').is_in([5, 6]))  # Saturday and Sunday\n",
    "df_sunday = df_all.filter(pl.col('weekday') == 6)  # Sunday only\n",
    "\n",
    "# Total number of data points across all scenarios\n",
    "total_data_points = df_all.shape[0]\n",
    "\n",
    "# Create box plots for each scenario\n",
    "scenarios = {\n",
    "    \"All Data\": df_all,\n",
    "    \"Weekdays Only\": df_weekdays,\n",
    "    \"Weekend Only\": df_weekend,\n",
    "    \"Sunday Only\": df_sunday\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(15, 12))  # 4 scenarios, 4 columns\n",
    "\n",
    "for i, (scenario_name, scenario_data) in enumerate(scenarios.items()):\n",
    "    for j, col in enumerate(['pm1', 'pm25', 'pm10', 'IR880']):\n",
    "        ax = axes[i, j]\n",
    "\n",
    "        # widths = compute_widths(data, total_data_points=total_data_points)\n",
    "        df_pd = scenario_data.to_pandas()\n",
    "        \n",
    "        # Create the box plot with proportional widths and light blue color\n",
    "        # box = data.boxplot(column=col, by='hour', ax=ax, widths=10*widths, patch_artist=True)\n",
    "        box = df_pd.boxplot(column=col, by='hour', ax=ax, patch_artist=True)\n",
    "        # for patch in box['boxes']:\n",
    "        #     patch.set_facecolor('lightblue')\n",
    "\n",
    "        # Set the x-axis to only show labels for 0, 6, 12, 18 hours\n",
    "        ax.set_xticks([0, 6, 12, 18])\n",
    "        ax.set_xticklabels('')\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_xticklabels(['0', '6', '12', '18'])\n",
    "\n",
    "        ax.set_title(f'{scenario_name} - {col}')\n",
    "        if i == 3:\n",
    "            ax.set_xlabel('Hour of day [UTC]')\n",
    "            # ax.set_xticklabels(['0', '6', '12', '18'])\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(f'Concentration [µg/m3]')\n",
    "        plt.suptitle(f\"{stations[0]} ({start} - {end})\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save results\n",
    "plt.savefig(os.path.join('results', f\"{stations[0]}_diurnal_variation.png\"))\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Return the filtered data\n",
    "filtered_data = {\n",
    "    \"all_data\": df_all,\n",
    "    \"df_weekdays\": df_weekdays,\n",
    "    \"df_weekend\": df_weekend,\n",
    "    \"df_sunday\": df_sunday\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import polars as pl\n",
    "# import hvplot.pandas  # Ensure hvplot is imported as part of pandas\n",
    "# import pandas as pd\n",
    "\n",
    "# # Convert the Polars DataFrame to Pandas\n",
    "# # df = df.to_pandas()\n",
    "\n",
    "# # Extract the hour and weekday from the datetime column\n",
    "# df['hour'] = df['dtm'].dt.hour\n",
    "# df['weekday'] = df['dtm'].dt.weekday\n",
    "# df['date'] = df['dtm'].dt.date  # Extract date to calculate the number of days\n",
    "\n",
    "# # Define scenarios\n",
    "# scenarios = {\n",
    "#     \"All Data\": df,\n",
    "#     \"Weekdays Only\": df[df['weekday'].between(0, 4)],  # Monday to Friday\n",
    "#     \"Weekend Only\": df[df['weekday'].isin([5, 6])],  # Saturday and Sunday\n",
    "#     \"Sunday Only\": df[df['weekday'] == 6]  # Sunday only\n",
    "# }\n",
    "\n",
    "# # Total number of data points across all scenarios\n",
    "# total_data_points = df.shape[0]\n",
    "\n",
    "# # Function to compute widths proportional to the number of data points\n",
    "# def compute_widths(data, total_data_points):\n",
    "#     # Count the number of unique days in the scenario\n",
    "#     num_days = data['date'].nunique()\n",
    "    \n",
    "#     # Group by hour and count the occurrences\n",
    "#     hour_counts = data.groupby('hour').size()\n",
    "    \n",
    "#     # Proportion of data points for each hour within the current scenario\n",
    "#     total_scenario_points = hour_counts.sum()\n",
    "#     relative_width_in_scenario = hour_counts / total_scenario_points\n",
    "    \n",
    "#     # Scale by the total data points proportion for the scenario\n",
    "#     relative_scenario_proportion = total_scenario_points / total_data_points\n",
    "#     final_widths = relative_width_in_scenario * relative_scenario_proportion\n",
    "    \n",
    "#     return final_widths\n",
    "\n",
    "# # Plotting\n",
    "# plots = []\n",
    "\n",
    "# for scenario_name, scenario_data in scenarios.items():\n",
    "#     widths = compute_widths(scenario_data, total_data_points)\n",
    "    \n",
    "#     # Create a box plot for each column\n",
    "#     for col in ['pm1', 'pm25', 'pm10', 'IR880']:\n",
    "#         plot = scenario_data.hvplot.box(\n",
    "#             y=col, by='hour', width=800, height=400,\n",
    "#             xlabel='Hour', ylabel=f'{col} Values',\n",
    "#             title=f'{scenario_name} - {col}',\n",
    "#             box_width=widths.to_dict()  # Pass the calculated widths\n",
    "#         )\n",
    "#         plots.append(plot)\n",
    "\n",
    "# # Combine the plots vertically\n",
    "# # hvplot.show(hvplot.Layout(plots).cols(1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
